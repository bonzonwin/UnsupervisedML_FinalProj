{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
    "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like mtcars, iris, palmer penguins etc.\n",
    "- The dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training an unsupervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
    "\n",
    "- The project must include some elements of unsupervised learning, but you are welcome to include some supervised or other learning approaches as well.\n",
    "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your ML system.\n",
    "- You will evaluate the performance of your ML system using more than one appropriate metric\n",
    "- You will be writing a report describing and discussing these accomplishments\n",
    "\n",
    "\n",
    "Feel free to delete this description section when you hand in your proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Banso Nguyen\n",
    "- Mijin\n",
    "- Ricky\n",
    "- Jason\n",
    "- Takumi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "In our model, we address the pervasive problem of email spam by developing a machine learning model that effectively differentiates between unwanted spam and legitimate ham emails. Utilizing a Kaggle dataset with 5170 emails, we aim to leverage both text content and metadata features to train our model. The emails are quantified by their textual content and metadata attributes, such as subject lines and sender information. Our approach will involve an initial phase of unsupervised learning, followed by the application of other techniques to refine the model's predictive accuracy. The performance of our model will be evaluated based on its precision, recall, and overall accuracy in correctly classifying emails into the respective categories. Through this methodology, we aim to reduce the incidence of false positives—where legitimate emails are incorrectly marked as spam—while maintaining a high detection rate of true spam messages, ensuring users receive important emails without the interference of unwanted content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "The digital age has brought with it an increasing reliance on email communication, paralleled by a rise of spam emails, which are unsolicited messages often sent in bulk for advertising, phishing, spreading malware, or fraud. Historically, spam constituted a minor nuisance, but it has evolved into a significant cybersecurity threat, with The Radicati Group reporting that spam emails accounted for 54% of all email traffic in mid-2021.\n",
    "\n",
    "After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds.<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#https://www.radicati.com/wp/wp-content/uploads/2020/12/Email-Statistics-Report–2021–2025–Executive-Summary.pdf)\n",
    "\n",
    "Initial efforts to combat spam relied on simple, rule-based filters, such as blacklisting certain senders or flagging messages containing specific keywords <a name=\"cite_ref-2\"></a>[<sup>2</sup>](#https://www.researchgate.net/publication/221650814_Spam_Filtering_with_Naive_Bayes_-_Which_Naive_Bayes) . However, spammers quickly adapted, evolving their strategies to evade these static defenses. As a result, the focus shifted towards more sophisticated, dynamic methods of detection.\n",
    "\n",
    "The advent of machine learning offered new prospects for spam detection. Supervised learning models, which require large sets of labeled data, have been effective but also labor-intensive and inflexible against spammers' ever-changing tactics <a name=\"cite_ref-3\"></a>[<sup>3</sup>](#https://dl.acm.org/doi/10.1145/1247715.1247717) . To address these issues, researchers began exploring unsupervised learning algorithms, which do not require pre-labeled datasets and are capable of detecting patterns and anomalies indicative of spam on their own <a name=\"cite_ref-4\"></a>[<sup>4</sup>](#https://link.springer.com/article/10.1007/s10462-009-9109-6). \n",
    "\n",
    "Clustering algorithms have been instrumental in unsupervised learning for spam detection, identifying natural groupings within data that can suggest common characteristics of spam or ham emails <a name=\"cite_ref-5\"></a>[<sup>5</sup>](#https://www.researchgate.net/publication/4096676_Adaptive_filtering_of_spam)  . Feature engineering has enhanced this process by identifying key characteristics from email content and metadata that are most indicative of spam, including message headers, the frequency of certain words, the use of HTML, and the inclusion of URLs <a name=\"cite_ref-6\"></a>[<sup>6</sup>](#https://www.researchgate.net/publication/258514273_Towards_SMS_Spam_Filtering_Results_under_a_New_Dataset)  \n",
    "\n",
    "Despite the potential of unsupervised learning, it is not without challenges. The varying nature of spam content, the continuous adaptation by spammers, and the risk of classifying legitimate emails as spam (false positives) complicate the model development process <a name=\"cite_ref-7\"></a>[<sup>7</sup>](#https://ieeexplore.ieee.org/document/788645) Furthermore, the lack of labeled data can make it difficult to assess the true performance of these models, which is why semi-supervised approaches that combine unsupervised clustering with a small set of labeled data for validation are gaining traction <a name=\"cite_ref-8\"></a>[<sup>8</sup>](#https://ieeexplore.ieee.org/document/1374241)\n",
    "\n",
    "In response to these challenges, our project aims to develop an unsupervised machine learning model capable of accurately identifying and segregating spam from legitimate emails. By leveraging unsupervised machine learning and sophisticated feature extraction techniques, we hope to build a model that not only detects current spam strategies but is also robust enough to adapt to future tactics used by spammers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Detecting spam mail relies on comparing spam email and non-spam email features. Our group will use machine learning and natural language processing techniques to explore which email feature(s) produce the highest precision and accuracy values when predicting spam mail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Link**: https://www.kaggle.com/datasets/venky73/spam-mails-dataset\n",
    "- **Description**: 4 variables, 5,170 observations. \n",
    "- **Each observation** consists of the email number, the label given to the emails determining whether they are spam or ham(not spam), the text of the email, and the one-hot encoded column for spam labels(1 for spam, 0 else). \n",
    "- **Critical variables**: \n",
    "  - Labels: Determining whether the emails are categorized as spam or not spam, represented using both text form and numerical form: Spam or Ham, or 1 for spam, 0 else.\n",
    "  - Text: The text of the email, useful for sentimental analysis to evaluate whether a given email is spam or not. Represented in the form in one string of the whole text. \n",
    "- **Cleaning/Transformations**:\n",
    "  - Clean out any invalid emails that might contain incomplete information.\n",
    "  - Check to see if every value in the dataset satisfies the correct type for each corresponding column. \n",
    "  - The text of the email might contain various elements that are not useful for spam classification, such as punctuation, special characters, numbers, and repetitive common words that provides no meaning to the identification of emails including \"and\", \"the\", \"is\", etc. Converting text to lowercase, and tokenizing the email text into individual words, and count the word frequencies(TF, or TF-IDF) for the whole dataset. \n",
    "  - Normalization: Perform stemming or lemmatization to reduce words to their root form. This helps in reducing the dimensionality of the feature space and can improve the performance of text classification algorithms.\n",
    "  - Split emails into subject, recipient, sender, etc for better categorization.\n",
    "  - More information coming soon...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "Our group will use the natural language toolkit (nitk) to tranform the different features we choose to run an unsupervised algorithm to reduce dimensionality and find the most prominent features. The initial algorithm we have in mind are PCA. We can use PCA to guess which features may be most prominent based on the results. After we find estimates of the most prominent features we will use them in classification algorithms such as logistic regression or random forests to classify if mail is spam or not and get accurcy and precision results. As a bench mark model we could possibly use a online accessible dataset (Enron Dataset) to compare with our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "One evaluation metric that can be used for the performance of the PCA is calculating the reconstruction error. It measures the dissimilartiy between the original data and the data reconstructed from the reduced-dimensional representation. The reconstruction error helps assess how well the reduced representation captures the important features of the original data. $$E_{recon} = \\frac{1}{N}\\sum_i=1^{N} ||X_{i}-\\hat{X_i}||^2$$ This is essentially calcuated the mean squared error of the Euclidean distances between the corresponding elements of the original and reconstructed data points. \n",
    "\n",
    "\n",
    "One evaluation metric that could be used to quantify the performance of the classification (supervised) model is the F-1 score. This score is the harmonic mean of precision and recall. $$F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall} $$ \n",
    "\n",
    "Precision is the ratio of correctly predicted positive observations to the total predicted positives. $$Precision = \\frac{True Positives}{True Positives+False Positives}$$ \n",
    "\n",
    "Recall is the ratio of correctly predicted positive observations to all the observations in the actuall class. \n",
    "$$Recall = \\frac{True Positives}{True Positives+False Negatives}$$\n",
    "\n",
    "\n",
    "Since F1 score considers both precision and recall, it provides a metric that considers false positives and false negatives. If we have a high F1=score, it means that we have a good balance between precision and recall. It is important to consider false positives and false negatives because we do not want non-spam emails to be considered as spam because they can contain important information and we do not want spam to infiltrate into the inbox. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination. Get creative!\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "\n",
    "* *Always communicate with each other through messages, or any other communication methods.*\n",
    "* *Contribute equal work with each other.*\n",
    "* *Review the work completed by other members and ask relevant questions.*\n",
    "* *Ask for help/clarification when needed.*\n",
    "* *Finish the assigned part of work on time for everyone.*\n",
    "* *When time conflicts, tell the group ASAP and work something out, either in person or online zoom meeting.*\n",
    "* *If a group member is not completing their portion of the project, they will be notified through email of the group’s expectations. If the outcome does not change, a TA or Professor will be notified.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/20  |  1 PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 1/26  |  10 AM |  Do background research on topic (Pelé) | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/1  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets (Beckenbaur)  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/14  | 6 PM  | Import & Wrangle Data ,do some EDA (Maradonna) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 2/23  | 12 PM  | Finalize wrangling/EDA; Begin programming for project (Cruyff) | Discuss/edit project code; Complete project |\n",
    "| 3/13  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Carlos)| Discuss/edit full project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
